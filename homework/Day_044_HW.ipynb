{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業重點]\n",
    "確保你了解隨機森林模型中每個超參數的意義，並觀察調整超參數對結果的影響"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業\n",
    "\n",
    "1. 試著調整 RandomForestClassifier(...) 中的參數，並觀察是否會改變結果？\n",
    "2. 改用其他資料集 (boston, wine)，並與回歸模型與決策樹的結果進行比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of DT : 21.09584274826357\n",
      "MAE of DT : 3.141036365298898\n"
     ]
    }
   ],
   "source": [
    "# 使用決策樹，對樹進行限制\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, mean_squared_error, mean_absolute_error\n",
    "import sklearn.datasets as datasets\n",
    "boston = datasets.load_boston()\n",
    "x_train, x_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size = 0.2, random_state = 15)\n",
    "clf = DecisionTreeRegressor(max_depth = 4, min_samples_split = 2,\n",
    "                           min_samples_leaf = 1, criterion='friedman_mse')\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(f'MSE of DT : {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'MAE of DT : {mean_absolute_error(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of RF : 11.33036844156864\n",
      "MAE of RF : 2.0061803921568693\n",
      "       name  importance\n",
      "12    LSTAT    0.452769\n",
      "5        RM    0.356478\n",
      "7       DIS    0.070875\n",
      "0      CRIM    0.029397\n",
      "4       NOX    0.022951\n",
      "10  PTRATIO    0.018890\n",
      "6       AGE    0.015298\n",
      "11        B    0.011863\n",
      "9       TAX    0.009662\n",
      "2     INDUS    0.006451\n",
      "8       RAD    0.003465\n",
      "3      CHAS    0.000993\n",
      "1        ZN    0.000909\n"
     ]
    }
   ],
   "source": [
    "# 使用1000棵樹，不對樹進行限制\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, mean_squared_error, mean_absolute_error\n",
    "import sklearn.datasets as datasets\n",
    "boston = datasets.load_boston()\n",
    "x_train, x_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size = 0.2, random_state = 15)\n",
    "clf = RandomForestRegressor(n_estimators=1000)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(f'MSE of RF : {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'MAE of RF : {mean_absolute_error(y_test, y_pred)}')\n",
    "import pandas as pd\n",
    "print(pd.DataFrame(data = zip(boston.feature_names, clf.feature_importances_),\n",
    "                   columns=['name', 'importance']).sort_values('importance', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of RF : 13.043877185023078\n",
      "MAE of RF : 2.276169548610828\n",
      "       name  importance\n",
      "12    LSTAT    0.485723\n",
      "5        RM    0.358030\n",
      "7       DIS    0.068567\n",
      "0      CRIM    0.025389\n",
      "4       NOX    0.019292\n",
      "10  PTRATIO    0.015396\n",
      "6       AGE    0.008168\n",
      "11        B    0.006651\n",
      "9       TAX    0.006278\n",
      "2     INDUS    0.003873\n",
      "8       RAD    0.001777\n",
      "3      CHAS    0.000553\n",
      "1        ZN    0.000303\n"
     ]
    }
   ],
   "source": [
    "# 使用1000棵樹，對樹進行限制\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, mean_squared_error, mean_absolute_error\n",
    "import sklearn.datasets as datasets\n",
    "boston = datasets.load_boston()\n",
    "x_train, x_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size = 0.2, random_state = 15)\n",
    "clf = RandomForestRegressor(n_estimators=1000, max_depth = 5)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(f'MSE of RF : {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'MAE of RF : {mean_absolute_error(y_test, y_pred)}')\n",
    "print(pd.DataFrame(data = zip(boston.feature_names, clf.feature_importances_),\n",
    "                   columns=['name', 'importance']).sort_values('importance', ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 增加對決策樹的限制後，模型表現反而變得較差。\n",
    "RF已透過投票的方式避免Overfitting了，不需要再透過限制樹來避免。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
